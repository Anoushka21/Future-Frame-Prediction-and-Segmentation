{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import argparse\n",
    "import logging\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "from dataset import MovingObjectsDataset\n",
    "from models import Generator, Discriminator\n",
    "from losses import SSIM, L1_L2_Loss\n",
    "from utils import init_log, add_file_handler, print_speed, Config, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(past_frames, true_future_frames, pred_future_frames,\n",
    "              past_frames_test, true_future_frames_test, pred_future_frames_test,\n",
    "              file_identifier, current_step, num_future_frame, writer):\n",
    "    \n",
    "    past_frames = torchvision.utils.make_grid(past_frames[0], num_future_frame)\n",
    "    true_future_frames = torchvision.utils.make_grid(true_future_frames[0], num_future_frame)\n",
    "    pred_future_frames = torchvision.utils.make_grid(pred_future_frames[0], num_future_frame)\n",
    "    past_frames_test = torchvision.utils.make_grid(past_frames_test[0], num_future_frame)\n",
    "    true_future_frames_test = torchvision.utils.make_grid(true_future_frames_test[0], num_future_frame)\n",
    "    pred_future_frames_test = torchvision.utils.make_grid(pred_future_frames_test[0], num_future_frame)\n",
    "    \n",
    "    os.makedirs(f\"../results/{file_identifier}/{current_step:06d}\", exist_ok=True)\n",
    "\n",
    "    plt.imsave(\n",
    "        f\"../results/{file_identifier}/{current_step:06d}/train_feed_seq.png\",\n",
    "        past_frames.cpu().permute(1, 2, 0).numpy()\n",
    "    )\n",
    "    plt.imsave(\n",
    "        f\"../results/{file_identifier}/{current_step:06d}/train_gt_seq.png\",\n",
    "        true_future_frames.cpu().permute(1, 2, 0).numpy(),\n",
    "    )\n",
    "    plt.imsave(\n",
    "        f\"../results/{file_identifier}/{current_step:06d}/train_pred_seq.png\",\n",
    "        pred_future_frames.detach().cpu().permute(1, 2, 0).numpy(),\n",
    "    )\n",
    "    plt.imsave(\n",
    "        f\"../results/{file_identifier}/{current_step:06d}/test_feed_seq.png\",\n",
    "        past_frames_test.cpu().permute(1, 2, 0).numpy(),\n",
    "    )\n",
    "    plt.imsave(\n",
    "        f\"../results/{file_identifier}/{current_step:06d}/test_gt_seq.png\",\n",
    "        true_future_frames_test.cpu().permute(1, 2, 0).numpy(),\n",
    "    )\n",
    "    plt.imsave(\n",
    "        f\"../results/{file_identifier}/{current_step:06d}/test_pred_seq.png\",\n",
    "        pred_future_frames_test.detach().cpu().permute(1, 2, 0).numpy(),\n",
    "    )\n",
    "    \n",
    "    writer.add_image(f\"train_feed_seq/{current_step:06d}\", past_frames, current_step)\n",
    "    writer.add_image(f\"train_gt_seq/{current_step:06d}\", true_future_frames, current_step)\n",
    "    writer.add_image(f\"train_pred_seq/{current_step:06d}\", pred_future_frames, current_step)\n",
    "    writer.add_image(f\"test_feed_seq/{current_step:06d}\", past_frames_test, current_step)\n",
    "    writer.add_image(f\"test_gt_seq/{current_step:06d}\", true_future_frames_test, current_step)\n",
    "    writer.add_image(f\"test_pred_seq/{current_step:06d}\", pred_future_frames_test, current_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg):\n",
    "    \"\"\"\n",
    "    Train loop\n",
    "    :param cfg: Config file path\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract and set up training parameters\n",
    "    cfg = Config(cfg)\n",
    "    lr = cfg.train[\"lr\"]\n",
    "    epochs = cfg.train[\"epochs\"]\n",
    "    board_path = cfg.meta[\"board_path\"]\n",
    "    batch_size = cfg.train[\"batch_size\"]\n",
    "    num_future_frame = cfg.model[\"future_frames\"]\n",
    "    print_freq = cfg.train[\"print_frequency\"]\n",
    "    img_size = cfg.model[\"input_size\"]\n",
    "    train_data_dir = cfg.meta[\"data_path_local_train\"]\n",
    "    test_data_dir = cfg.meta[\"data_path_local_test\"]\n",
    "    file_identifier = f'{batch_size}_{epochs}_{img_size[0]}{img_size[1]}'\n",
    "\n",
    "    avg = AverageMeter()\n",
    "\n",
    "    device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Create dataloaders for train and test dataset\n",
    "    train_dataset = MovingObjectsDataset(\n",
    "        root_dir=f'{train_data_dir}',\n",
    "        transform=transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize((img_size[0], img_size[1])),\n",
    "                    transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=1)\n",
    "\n",
    "\n",
    "    test_dataset = MovingObjectsDataset(\n",
    "        root_dir=f'{test_data_dir}',\n",
    "        transform=transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize((img_size[0], img_size[1])),\n",
    "                    transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=1)\n",
    "\n",
    "    test_iter = iter(test_loader)\n",
    "\n",
    "    os.makedirs(os.path.join(os.getcwd(), f\"logs/{file_identifier}\"), exist_ok=True)\n",
    "    global_logger = init_log(\"global\", level=logging.INFO)\n",
    "    add_file_handler(\"global\", os.path.join(os.getcwd(), f\"logs/{file_identifier}\", \"train.log\"), level=logging.DEBUG)\n",
    "\n",
    "    global_logger.debug(\"==>>> Total training batches: {}\".format(len(train_loader)))\n",
    "    global_logger.debug(\"==>>> Total testing batches: {}\".format(len(test_loader)))\n",
    "\n",
    "    writer = SummaryWriter(os.path.join(\".\", board_path))\n",
    "\n",
    "    # Create Generator and Discriminator models\n",
    "    generator = Generator(cfg=cfg.model, device=device)\n",
    "    generator.to(device)\n",
    "\n",
    "    discriminator = Discriminator(cfg=cfg.model)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    # Define optimizers and LR Schedulers\n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "    generator_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer=generator_optimizer, milestones=[10, 20, 30, 40], gamma=0.5\n",
    "    )\n",
    "    discriminator_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer=discriminator_optimizer, milestones=[10, 20, 30, 40], gamma=0.5\n",
    "    )\n",
    "\n",
    "    # Distribute training across multiple GPUs\n",
    "    generator = nn.DataParallel(generator)\n",
    "    discriminator = nn.DataParallel(discriminator)\n",
    "\n",
    "    # Begin training (restart from checkpoint if possible)\n",
    "    start_epoch = 0\n",
    "    if os.path.isfile(f\"../model/model_{file_identifier}.pt\"):\n",
    "        print(\"Restarting training...\")\n",
    "        checkpoint = torch.load(f\"../model/model_{file_identifier}.pt\")\n",
    "        generator.load_state_dict(checkpoint[\"generator_state_dict\"])\n",
    "        generator_optimizer.load_state_dict(checkpoint[\"generator_optimizer_state_dict\"])\n",
    "        discriminator.load_state_dict(checkpoint[\"discriminator_state_dict\"])\n",
    "        discriminator_optimizer.load_state_dict(checkpoint[\"discriminator_optimizer_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "    # Define losses\n",
    "    ssim_loss = SSIM(window_size=11, size_average=True).to(device)\n",
    "    l1_l2_loss = L1_L2_Loss().to(device)\n",
    "    adversarial_loss = torch.nn.BCELoss().to(device)\n",
    "\n",
    "    # Value trackers\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    train_metric_list = []\n",
    "    test_metric_list = []\n",
    "\n",
    "    # Train loop\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        for step, [past_frames, true_future_frames] in enumerate(train_loader):\n",
    "            start_time = time.time()\n",
    "\n",
    "            generator.train()\n",
    "            discriminator.train()\n",
    "\n",
    "            if epoch == 0 and step == 0:\n",
    "                global_logger.debug(\"Input:  {}\".format(past_frames.shape))\n",
    "                global_logger.debug(\"--- Sample\")\n",
    "                global_logger.debug(\"Target: {}\".format(true_future_frames.shape))\n",
    "\n",
    "            past_frames, true_future_frames = past_frames.to(device), true_future_frames.to(device)\n",
    "            pred_future_frames = generator(past_frames, future=num_future_frame)\n",
    "\n",
    "            # Train discriminator to classify real and predicted frames with label smoothing\n",
    "            discriminator.zero_grad()\n",
    "            seq_target_frames = true_future_frames.squeeze().view(-1, *true_future_frames.shape[3:])\n",
    "            label = torch.empty(seq_target_frames.size(0), device=device).uniform_(0.9, 1)\n",
    "            output = discriminator(seq_target_frames).view(-1)\n",
    "            discriminator_loss_real = adversarial_loss(output, label)\n",
    "\n",
    "            predicted_future_frames_individual = pred_future_frames.squeeze().view(-1, *true_future_frames.shape[3:])\n",
    "            label = torch.empty(predicted_future_frames_individual.size(0), device=device).uniform_(0, 0.1)\n",
    "            output = discriminator(predicted_future_frames_individual).view(-1)\n",
    "            discriminator_loss_fake = adversarial_loss(output, label)\n",
    "\n",
    "            discriminator_loss = discriminator_loss_real + discriminator_loss_fake\n",
    "            discriminator_loss.backward(retain_graph=True)\n",
    "            discriminator_optimizer.step()\n",
    "\n",
    "            # Train generator with adversarial loss with label smoothing\n",
    "            generator.zero_grad()\n",
    "            label = torch.empty(predicted_future_frames_individual.size(0), device=device).uniform_(0.9, 1)\n",
    "            output = discriminator(predicted_future_frames_individual).view(-1)\n",
    "\n",
    "            # Weighted loss for generator model with emphasis on image quality\n",
    "            generator_loss = adversarial_loss(output, label) + 4 * l1_l2_loss(\n",
    "                pred_future_frames[:, -num_future_frame:, :, :, :], true_future_frames[:, -num_future_frame:, :, :, :]\n",
    "            )\n",
    "\n",
    "            generator_loss.backward(retain_graph=True)\n",
    "            generator_optimizer.step()\n",
    "\n",
    "            # Evaluate and test the model\n",
    "            with torch.no_grad():\n",
    "                train_metric = ssim_loss(\n",
    "                    pred_future_frames[:, -num_future_frame:, :, :, :],\n",
    "                    true_future_frames[:, -num_future_frame:, :, :, :],\n",
    "                )\n",
    "\n",
    "                try:\n",
    "                    past_frames_test, true_future_frames_test = next(test_iter)\n",
    "                except StopIteration:\n",
    "                    test_iter = iter(test_loader)\n",
    "                    past_frames_test, true_future_frames_test = next(test_iter)\n",
    "\n",
    "                past_frames_test = past_frames_test.to(device)\n",
    "                true_future_frames_test = true_future_frames_test.to(device)\n",
    "                pred_future_frames_test = generator(past_frames_test, future=num_future_frame)\n",
    "\n",
    "                test_loss = l1_l2_loss(\n",
    "                    pred_future_frames_test[:, -num_future_frame:, :, :, :],\n",
    "                    true_future_frames_test[:, -num_future_frame:, :, :, :],\n",
    "                )\n",
    "                test_metric = ssim_loss(\n",
    "                    pred_future_frames_test[:, -num_future_frame:, :, :, :],\n",
    "                    true_future_frames_test[:, -num_future_frame:, :, :, :],\n",
    "                )\n",
    "\n",
    "            # Log values and store the model outputs on main worker\n",
    "            step_time = time.time() - start_time\n",
    "\n",
    "            train_loss_list.append(generator_loss.item())\n",
    "            test_loss_list.append(test_loss.item())\n",
    "            train_metric_list.append(train_metric.item())\n",
    "            test_metric_list.append(test_metric.item())\n",
    "\n",
    "            \n",
    "\n",
    "            if (step + 1) % print_freq == 0:\n",
    "                current_step = epoch * len(train_loader) + step + 1\n",
    "                \n",
    "                visualize(past_frames, true_future_frames, pred_future_frames,\n",
    "                          past_frames_test, true_future_frames_test, pred_future_frames_test,\n",
    "                          file_identifier, current_step, num_future_frame, writer)\n",
    "\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"generator_state_dict\": generator.state_dict(),\n",
    "                        \"generator_optimizer_state_dict\": generator_optimizer.state_dict(),\n",
    "                        \"discriminator_state_dict\": discriminator.state_dict(),\n",
    "                        \"discriminator_optimizer_state_dict\": discriminator_optimizer.state_dict(),\n",
    "                    },\n",
    "                    f\"../model/model_{file_identifier}.pt\",\n",
    "                )\n",
    "\n",
    "            writer.add_scalars(\n",
    "                f\"loss/{file_identifier}/merge\",\n",
    "                {\n",
    "                    \"generator_loss\": generator_loss.item(),\n",
    "                    \"discriminator_loss\": discriminator_loss.item(),\n",
    "                    \"test_loss\": test_loss.item(),\n",
    "                    \"train_metric\": train_metric.item(),\n",
    "                    \"test_metric\": test_metric.item(),\n",
    "                },\n",
    "                epoch * len(train_loader) + step + 1,\n",
    "            )\n",
    "\n",
    "            avg.update(\n",
    "                step_time=step_time,\n",
    "                generator_loss=generator_loss.item(),\n",
    "                discriminator_loss=discriminator_loss.item(),\n",
    "                test_loss=test_loss.item(),\n",
    "                train_metric=train_metric.item(),\n",
    "            )\n",
    "\n",
    "            if (step + 1) % print_freq == 0:\n",
    "                global_logger.info(\n",
    "                    \"Epoch: [{0}][{1}/{2}] {Step_Time:s}\\t{Gen_loss:s}\\t{Disc_loss:s}\\t{Test_loss:s}\\t{Train_metric:s}\".format(\n",
    "                        epoch + 1,\n",
    "                        (step + 1) % len(train_loader),\n",
    "                        len(train_loader),\n",
    "                        Step_Time=avg.step_time,\n",
    "                        Gen_loss=avg.generator_loss,\n",
    "                        Disc_loss=avg.discriminator_loss,\n",
    "                        Test_loss=avg.test_loss,\n",
    "                        Train_metric=avg.train_metric,\n",
    "                    )\n",
    "                )\n",
    "                print_speed(epoch * len(train_loader) + step + 1, avg.step_time.avg, epochs * len(train_loader))\n",
    "\n",
    "        generator_scheduler.step()\n",
    "        discriminator_scheduler.step()\n",
    "        gc.collect()\n",
    "\n",
    "    with open(f\"../results/{file_identifier}/train_loss_list.pkl\", \"wb\") as f:\n",
    "        pickle.dump(train_loss_list, f)\n",
    "    with open(f\"../results/{file_identifier}/test_loss_list.pkl\", \"wb\") as f:\n",
    "        pickle.dump(test_loss_list, f)\n",
    "\n",
    "    with open(f\"../results/{file_identifier}/train_metric_list.pkl\", \"wb\") as f:\n",
    "        pickle.dump(train_metric_list, f)\n",
    "    with open(f\"../results/{file_identifier}/test_metric_list.pkl\", \"wb\") as f:\n",
    "        pickle.dump(test_metric_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-02 16:26:01,761-565752610.py#234] [INFO] Epoch: [1][1/6] step_time: 12.583880 (12.583880)\tgenerator_loss: 0.974485 (0.974485)\tdiscriminator_loss: 1.387214 (1.387214)\ttest_loss: 0.064507 (0.064507)\ttrain_metric: 0.427318 (0.427318)\n",
      "[2023-05-02 16:26:01,766-utils.py#187] [INFO] Progress: 1 / 12 [8%], Speed: 12.584 s/iter, ETA 0:00:02 (D:H:M)\n",
      "\n",
      "[2023-05-02 16:26:16,150-565752610.py#234] [INFO] Epoch: [1][2/6] step_time: 14.129702 (13.356791)\tgenerator_loss: 0.901872 (0.938178)\tdiscriminator_loss: 1.391533 (1.389374)\ttest_loss: 0.058900 (0.061703)\ttrain_metric: 0.435375 (0.431346)\n",
      "[2023-05-02 16:26:16,156-utils.py#187] [INFO] Progress: 2 / 12 [16%], Speed: 13.357 s/iter, ETA 0:00:02 (D:H:M)\n",
      "\n",
      "[2023-05-02 16:26:37,365-565752610.py#234] [INFO] Epoch: [1][3/6] step_time: 20.975193 (15.896258)\tgenerator_loss: 0.972877 (0.949744)\tdiscriminator_loss: 1.420303 (1.399684)\ttest_loss: 0.058511 (0.060639)\ttrain_metric: 0.451863 (0.438185)\n",
      "[2023-05-02 16:26:37,370-utils.py#187] [INFO] Progress: 3 / 12 [25%], Speed: 15.896 s/iter, ETA 0:00:02 (D:H:M)\n",
      "\n",
      "[2023-05-02 16:26:52,005-565752610.py#234] [INFO] Epoch: [1][4/6] step_time: 14.385398 (15.518543)\tgenerator_loss: 0.984579 (0.958453)\tdiscriminator_loss: 1.379348 (1.394600)\ttest_loss: 0.054562 (0.059120)\ttrain_metric: 0.461061 (0.443904)\n",
      "[2023-05-02 16:26:52,025-utils.py#187] [INFO] Progress: 4 / 12 [33%], Speed: 15.519 s/iter, ETA 0:00:02 (D:H:M)\n",
      "\n",
      "[2023-05-02 16:27:13,334-565752610.py#234] [INFO] Epoch: [1][5/6] step_time: 21.048194 (16.624473)\tgenerator_loss: 0.930331 (0.952829)\tdiscriminator_loss: 1.395000 (1.394680)\ttest_loss: 0.054270 (0.058150)\ttrain_metric: 0.485669 (0.452257)\n",
      "[2023-05-02 16:27:13,345-utils.py#187] [INFO] Progress: 5 / 12 [41%], Speed: 16.624 s/iter, ETA 0:00:01 (D:H:M)\n",
      "\n",
      "[2023-05-02 16:27:28,330-565752610.py#234] [INFO] Epoch: [1][0/6] step_time: 14.737122 (16.309915)\tgenerator_loss: 0.852772 (0.936152)\tdiscriminator_loss: 1.388272 (1.393612)\ttest_loss: 0.050442 (0.056865)\ttrain_metric: 0.514388 (0.462612)\n",
      "[2023-05-02 16:27:28,334-utils.py#187] [INFO] Progress: 6 / 12 [50%], Speed: 16.310 s/iter, ETA 0:00:01 (D:H:M)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train('config_local.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"-c\",\n",
    "        \"--cfg\",\n",
    "        default=os.path.join(os.getcwd(), \"config.json\"),\n",
    "        type=str,\n",
    "        required=False,\n",
    "        help=\"Training config file path\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    cfg = Config(cfg)\n",
    "    lr = cfg.train[\"lr\"]\n",
    "    epochs = cfg.train[\"epochs\"]\n",
    "    board_path = cfg.meta[\"board_path\"]\n",
    "    batch_size = cfg.train[\"batch_size\"]\n",
    "    num_future_frame = cfg.model[\"future_frames\"]\n",
    "    print_freq = cfg.train[\"print_frequency\"]\n",
    "    img_size = cfg.model[\"input_size\"]\n",
    "    train_data_dir = cfg.meta[\"data_path_local_train\"]\n",
    "    test_data_dir = cfg.meta[\"data_path_local_test\"]\n",
    "    file_identifier = f'{batch_size}_{epochs}_{img_size[0]}{img_size[1]}'\n",
    "    cfg.log_dict()\n",
    "    \n",
    "    train(args.cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dls-assignment",
   "language": "python",
   "name": "dls-assignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
